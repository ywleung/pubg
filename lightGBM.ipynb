{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gc, sys\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = pd.read_csv('train_V2.csv')\n",
    "# drop the row with missing value\n",
    "train.drop(train[train['winPlacePerc'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reduce memory usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    #start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    #end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory usage of train_df\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to undergo feature engineering\n",
    "def feature_engineering(df, is_train=True):\n",
    "    # fix rank points\n",
    "    df['rankPoints'] = np.where(df['rankPoints'] <= 0, 0, df['rankPoints'])\n",
    "    \n",
    "    print('adding new features...')\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "    df['headshotrate'] = df['kills'] / df['headshotKills']\n",
    "    df['killStreakrate'] = df['killStreaks'] / df['kills']\n",
    "    df['healthitems'] = df['heals'] + df['boosts']\n",
    "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
    "    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
    "    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n",
    "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
    "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
    "    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n",
    "    df[\"skill\"] = df[\"headshotKills\"]+df[\"roadKills\"]\n",
    "    \n",
    "    df[df == np.Inf] = np.NaN\n",
    "    df[df == np.NINF] = np.NaN\n",
    "    \n",
    "    print(\"Removing Na's From DF\")\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    print(df.isnull().any().any())\n",
    "    \n",
    "    target = 'winPlacePerc'\n",
    "    features = list(df.columns)\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchType\")\n",
    "    \n",
    "    y = None\n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        features.remove(target)\n",
    "    \n",
    "    print(\"adding group mean feature...\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()    \n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # new\n",
    "    # print(\"get group median feature\")\n",
    "    # agg = df.groupby(['matchId','groupId'])[features].agg('median')\n",
    "    # agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    # df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    # df_out = df_out.merge(agg_rank, suffixes=[\"_median\", \"_median_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"adding group max feature...\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"adding group min feature...\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # new\n",
    "#     print(\"get group sum feature\")\n",
    "#     agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n",
    "#     agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "#     df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "#     df_out = df_out.merge(agg_rank, suffixes=[\"_sum\", \"_sum_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"adding group size feature...\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"adding match mean feature...\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # new\n",
    "#     print(\"adding match sum feature\")\n",
    "#     agg = df.groupby(['matchId'])[features].agg('sum').reset_index()\n",
    "#     df_out = df_out.merge(agg, suffixes=[\"\", \"_match_sum\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # new\n",
    "#     print(\"adding match median feature\")\n",
    "#     agg = df.groupby(['matchId'])[features].agg('median').reset_index()\n",
    "#     df_out = df_out.merge(agg, suffixes=[\"\", \"_match_median\"], how='left', on=['matchId'])\n",
    "    \n",
    "    print(\"adding match size feature...\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    \n",
    "    del df, agg, agg_rank\n",
    "    gc.collect()\n",
    "    sleep(30)\n",
    "    \n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "\n",
    "    df_out = np.array(df_out, dtype=np.float64)\n",
    "\n",
    "#     del df, df_out, agg, agg_rank\n",
    "#     gc.collect()\n",
    "\n",
    "    return df_out, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding new features...\n",
      "Removing Na's From DF\n",
      "False\n",
      "adding group mean feature...\n",
      "adding group max feature...\n",
      "adding group min feature...\n",
      "adding group size feature...\n",
      "adding match mean feature...\n",
      "adding match size feature...\n"
     ]
    }
   ],
   "source": [
    "# feature engineering to train_df\n",
    "X_df, y_df = feature_engineering(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train_df\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(X_df)\n",
    "X_df = scaler.transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to run light gbm model\n",
    "def run_lgb(X_train, y_train, X_val, y_val):\n",
    "    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators':20000, 'early_stopping_rounds':200,\n",
    "              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.7,\n",
    "               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n",
    "             }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    lgval = lgb.Dataset(X_val, label=y_val)\n",
    "    model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgval], early_stopping_rounds=200, verbose_eval=1000)\n",
    "    \n",
    "    # pred_test_y = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    # return pred_test_y, model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywleung\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\ywleung\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 0.0282865\tvalid_1's l1: 0.028793\n",
      "[2000]\ttraining's l1: 0.0270618\tvalid_1's l1: 0.0279507\n",
      "[3000]\ttraining's l1: 0.026262\tvalid_1's l1: 0.027516\n",
      "[4000]\ttraining's l1: 0.0256278\tvalid_1's l1: 0.0272223\n",
      "[5000]\ttraining's l1: 0.0250771\tvalid_1's l1: 0.0269997\n",
      "[6000]\ttraining's l1: 0.0245995\tvalid_1's l1: 0.0268379\n",
      "[7000]\ttraining's l1: 0.0241504\tvalid_1's l1: 0.0266885\n",
      "[8000]\ttraining's l1: 0.0237384\tvalid_1's l1: 0.0265655\n",
      "[9000]\ttraining's l1: 0.0233432\tvalid_1's l1: 0.0264533\n",
      "[10000]\ttraining's l1: 0.022967\tvalid_1's l1: 0.026343\n",
      "[11000]\ttraining's l1: 0.0226047\tvalid_1's l1: 0.026239\n",
      "[12000]\ttraining's l1: 0.0222584\tvalid_1's l1: 0.0261443\n",
      "[13000]\ttraining's l1: 0.0219242\tvalid_1's l1: 0.0260544\n",
      "[14000]\ttraining's l1: 0.0216077\tvalid_1's l1: 0.0259765\n",
      "[15000]\ttraining's l1: 0.0212985\tvalid_1's l1: 0.0258979\n",
      "[16000]\ttraining's l1: 0.0210054\tvalid_1's l1: 0.0258299\n",
      "[17000]\ttraining's l1: 0.0207269\tvalid_1's l1: 0.0257754\n",
      "[18000]\ttraining's l1: 0.0204466\tvalid_1's l1: 0.0257132\n",
      "[19000]\ttraining's l1: 0.0201777\tvalid_1's l1: 0.0256516\n",
      "[20000]\ttraining's l1: 0.0199181\tvalid_1's l1: 0.0255987\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's l1: 0.0199181\tvalid_1's l1: 0.0255987\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_df, y_df, test_size=0.2)\n",
    "# Training the model #\n",
    "model = run_lgb(X_train, y_train, X_val, y_val)\n",
    "\n",
    "del X_df, y_df, X_train, y_train, X_val, y_val\n",
    "gc.collect()\n",
    "sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding new features...\n",
      "Removing Na's From DF\n",
      "False\n",
      "adding group mean feature...\n",
      "adding group max feature...\n",
      "adding group min feature...\n",
      "adding group size feature...\n",
      "adding match mean feature...\n",
      "adding match size feature...\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('test_V2.csv')\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "X_test, _ = feature_engineering(X_test, False)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999 199999 299999 399999 499999 599999 699999 799999 899999 999999 1099999 1199999 1299999 1399999 1499999 1599999 1699999 1799999 1899999 "
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('test_V2.csv')\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    winPlacePerc = pred[i]\n",
    "    maxPlace = int(X_test.iloc[i]['maxPlace'])\n",
    "    if maxPlace == 0:\n",
    "        winPlacePerc = 0.0\n",
    "    elif maxPlace == 1:\n",
    "        winPlacePerc = 1.0\n",
    "    else:\n",
    "        gap = 1.0 / (maxPlace - 1)\n",
    "        winPlacePerc = round(winPlacePerc / gap) * gap\n",
    "    \n",
    "    if winPlacePerc < 0: winPlacePerc = 0.0\n",
    "    if winPlacePerc > 1: winPlacePerc = 1.0    \n",
    "    pred[i] = winPlacePerc\n",
    "\n",
    "    if (i + 1) % 100000 == 0:\n",
    "        print(i, flush=True, end=\" \")\n",
    "        \n",
    "\n",
    "X_test['winPlacePerc'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = X_test[['Id', 'winPlacePerc']]\n",
    "submission.to_csv('submission_NN_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
